import h5py
import math
import nibabel as nib
import numpy as np
from medpy import metric
import torch
import torch.nn.functional as F
from tqdm import tqdm
from skimage.measure import label
from utils.BCP_utils import context_mask

def getLargestCC(segmentation):
    labels = label(segmentation)
    #assert( labels.max() != 0 ) # assume at least 1 CC
    if labels.max() != 0:
        largestCC = labels == np.argmax(np.bincount(labels.flat)[1:])+1
    else:
        largestCC = segmentation
    return largestCC

def var_all_case_LA(model, num_classes, patch_size=(112, 112, 80), stride_xy=18, stride_z=4):
   
    with open('data/LA/test.list', 'r') as f:
        image_list = f.readlines()
    image_list = ["data/LA/2018LA_Seg/" + item.replace('\n', '') + "/mri_norm2.h5" for item in image_list]
    loader = tqdm(image_list)
    total_dice = 0.0
    for image_path in loader:
        h5f = h5py.File(image_path, 'r')
        image = h5f['image'][:]
        label = h5f['label'][:]
        prediction, score_map = test_single_case(model, image, stride_xy, stride_z, patch_size, num_classes=num_classes)
        if np.sum(prediction)==0:
            dice = 0
        else:
            dice = metric.binary.dc(prediction, label)
        total_dice += dice
    avg_dice = total_dice / len(image_list)
    print('average metric is {}'.format(avg_dice))
    return avg_dice


def var_all_case_BraTS(model, num_classes, patch_size=(96, 96, 96), stride_xy=64, stride_z=64):
    with open('data/BraTS2019/val.txt', 'r') as f:
        image_list = f.readlines()
    image_list = ["data/BraTS2019/data/{}.h5".format(item.replace('\n', '').split(",")[0]) for item in image_list]
    loader = tqdm(image_list)
    total_dice = 0.0
    for image_path in loader:
        h5f = h5py.File(image_path, 'r')
        image = h5f['image'][:]
        label = h5f['label'][:]
        prediction, score_map = test_single_case(model, image, stride_xy, stride_z, patch_size, num_classes=num_classes)
        if np.sum(prediction) == 0:
            dice = 0
        else:
            dice = metric.binary.dc(prediction, label)
        total_dice += dice
    avg_dice = total_dice / len(image_list)
    print('average metric is {}'.format(avg_dice))
    return avg_dice

def test_all_case_double(model, image_list, num_classes, patch_size=(112, 112, 80), stride_xy=18, stride_z=4, save_result=True, test_save_path=None, preproc_fn=None, metric_detail=0, nms=0):
    loader = tqdm(image_list) if not metric_detail else image_list
    total_metric = 0.0
    ith = 0
    num_imgs = len(image_list)
    for i in range(0, num_imgs, 2):
        # id = image_path.split('/')[-2]
        image_path_1 = image_list[i]
        image_path_2 = image_list[i+1]
        h5f_1 = h5py.File(image_path_1, 'r')
        image_1 = h5f_1['image'][:]
        label_1 = h5f_1['label'][:]
        h5f_2 = h5py.File(image_path_2, 'r')
        image_2 = h5f_2['image'][:]
        label_2 = h5f_2['label'][:]
        if preproc_fn is not None:
            image_1 = preproc_fn(image_1)
            image_2 = preproc_fn(image_2)
        prediction_1, score_map_1, prediction_2, score_map_2 = test_double_case(model, image_1, image_2, stride_xy, stride_z, patch_size, num_classes=num_classes)
        if nms:
            prediction_1 = getLargestCC(prediction_1)
            prediction_2 = getLargestCC(prediction_2)

        if np.sum(prediction_1) == 0:
            single_metric_1 = (0, 0, 0, 0)
        else:
            single_metric_1 = calculate_metric_percase(prediction_1, label_1[:])

        if np.sum(prediction_2) == 0:
            single_metric_2 = (0, 0, 0, 0)
        else:
            single_metric_2 = calculate_metric_percase(prediction_2, label_2[:])

        if metric_detail:
            print('%02d,\t%.5f, %.5f, %.5f, %.5f' % (
                ith, single_metric_1[0], single_metric_1[1], single_metric_1[2], single_metric_1[3]))
            print('%02d,\t%.5f, %.5f, %.5f, %.5f' % (
                ith+1, single_metric_2[0], single_metric_2[1], single_metric_2[2], single_metric_2[3]))

        total_metric += np.asarray(single_metric_1)
        total_metric += np.asarray(single_metric_2)

        # if save_result:
        #     nib.save(nib.Nifti1Image(prediction_1.astype(np.float32), np.eye(4)),
        #              test_save_path + "%02d_pred.nii.gz" % ith)
        #     # nib.save(nib.Nifti1Image(score_map[0].astype(np.float32), np.eye(4)), test_save_path +  "%02d_scores.nii.gz" % ith)
        #     nib.save(nib.Nifti1Image(image[:].astype(np.float32), np.eye(4)), test_save_path + "%02d_img.nii.gz" % ith)
        #     nib.save(nib.Nifti1Image(label[:].astype(np.float32), np.eye(4)), test_save_path + "%02d_gt.nii.gz" % ith)
        ith += 2

    avg_metric = total_metric / len(image_list)
    print('average metric is {}'.format(avg_metric))

    with open(test_save_path + '../performance.txt', 'w') as f:
        f.writelines('average metric is {} \n'.format(avg_metric))
    return avg_metric

def test_all_case(model, image_list, num_classes, patch_size=(112, 112, 80), stride_xy=64, stride_z=64, save_result=True, test_save_path=None, preproc_fn=None, metric_detail=0, nms=0):
    
    loader = tqdm(image_list) if not metric_detail else image_list
    total_metric = 0.0
    ith = 0
    for image_path in loader:
        # id = image_path.split('/')[-2]
        h5f = h5py.File(image_path, 'r')
        image = h5f['image'][:]
        label = h5f['label'][:]
        if preproc_fn is not None:
            image = preproc_fn(image)
        prediction, score_map = test_single_case(model, image, stride_xy, stride_z, patch_size, num_classes=num_classes)
        if nms:
            prediction = getLargestCC(prediction)

        if np.sum(prediction)==0:
            single_metric = (0,0,0,0)
        else:
            single_metric = calculate_metric_percase(prediction, label[:])
            
        if metric_detail:
            print('%02d,\t%.5f, %.5f, %.5f, %.5f' % (ith, single_metric[0], single_metric[1], single_metric[2], single_metric[3]))

        total_metric += np.asarray(single_metric)
        
        if save_result:
            nib.save(nib.Nifti1Image(prediction.astype(np.float32), np.eye(4)), test_save_path +  "%02d_pred.nii.gz" % ith)
            #nib.save(nib.Nifti1Image(score_map[0].astype(np.float32), np.eye(4)), test_save_path +  "%02d_scores.nii.gz" % ith)
            nib.save(nib.Nifti1Image(image[:].astype(np.float32), np.eye(4)), test_save_path + "%02d_img.nii.gz" % ith)
            nib.save(nib.Nifti1Image(label[:].astype(np.float32), np.eye(4)), test_save_path + "%02d_gt.nii.gz" % ith)
        ith += 1

    avg_metric = total_metric / len(image_list)
    print('average metric is {}'.format(avg_metric))

    with open(test_save_path+'../performance.txt', 'w') as f:
        f.writelines('average metric is {} \n'.format(avg_metric))
    return avg_metric

def test_double_case(model, image_1, image_2, stride_xy, stride_z, patch_size, num_classes=1):
    w1, h1, d1 = image_1.shape
    w2, h2, d2 = image_2.shape
    wf = max(w1, w2)
    hf = max(h1, h2)
    df = max(d1, d2)
    wpad1 = wf - w1
    wpad2 = wf - w2
    hpad1 = hf - h1
    hpad2 = hf - h2
    dpad1 = df - d1
    dpad2 = df - d2
    wlpad1, wrpad1, wlpad2, wrpad2 = wpad1 // 2, wpad1 - wpad1 // 2, wpad2 // 2, wpad2 - wpad2 // 2
    hlpad1, hrpad1, hlpad2, hrpad2 = hpad1 // 2, hpad1 - hpad1 // 2, hpad2 // 2, hpad2 - hpad2 // 2
    dlpad1, drpad1, dlpad2, drpad2 = dpad1 // 2, dpad1 - dpad1 // 2, dpad2 // 2, dpad2 - dpad2 // 2
    image_1 = np.pad(image_1, [(wlpad1, wrpad1), (hlpad1, hrpad1), (dlpad1, drpad1)], mode='constant', constant_values=0)
    image_2 = np.pad(image_2, [(wlpad2, wrpad2), (hlpad2, hrpad2), (dlpad2, drpad2)], mode='constant', constant_values=0)
    w, h, d = wf, hf, df
    add_pad = False
    if w < patch_size[0]:
        w_pad = patch_size[0] - w
        add_pad = True
    else:
        w_pad = 0
    if h < patch_size[1]:
        h_pad = patch_size[1] - h
        add_pad = True
    else:
        h_pad = 0
    if d < patch_size[2]:
        d_pad = patch_size[2] - d
        add_pad = True
    else:
        d_pad = 0
    wl_pad, wr_pad = w_pad // 2, w_pad - w_pad // 2
    hl_pad, hr_pad = h_pad // 2, h_pad - h_pad // 2
    dl_pad, dr_pad = d_pad // 2, d_pad - d_pad // 2
    if add_pad:
        image_1 = np.pad(image_1, [(wl_pad, wr_pad), (hl_pad, hr_pad), (dl_pad, dr_pad)], mode='constant', constant_values=0)
        image_2 = np.pad(image_2, [(wl_pad, wr_pad), (hl_pad, hr_pad), (dl_pad, dr_pad)], mode='constant', constant_values=0)
    ww, hh, dd = image_1.shape
    sx = math.ceil((ww - patch_size[0]) / stride_xy) + 1
    sy = math.ceil((hh - patch_size[1]) / stride_xy) + 1
    sz = math.ceil((dd - patch_size[2]) / stride_z) + 1
    # print("{}, {}, {}".format(sx, sy, sz))
    score_map_1_o = np.zeros((num_classes,) + image_1.shape).astype(np.float32)
    score_map_1_m = np.zeros((num_classes,) + image_1.shape).astype(np.float32)
    score_map_2_o = np.zeros((num_classes,) + image_2.shape).astype(np.float32)
    score_map_2_m = np.zeros((num_classes,) + image_2.shape).astype(np.float32)
    cnt = np.zeros(image_1.shape).astype(np.float32)
    mask_ratio = 2 / 3
    for x in range(0, sx):
        xs = min(stride_xy*x, ww-patch_size[0])
        for y in range(0, sy):
            ys = min(stride_xy * y,hh-patch_size[1])
            for z in range(0, sz):
                zs = min(stride_z * z, dd-patch_size[2])
                test_patch_1 = image_1[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]]
                test_patch_2 = image_2[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]]
                test_patch_1 = np.expand_dims(np.expand_dims(test_patch_1, axis=0), axis=0).astype(np.float32)
                test_patch_2 = np.expand_dims(np.expand_dims(test_patch_2, axis=0), axis=0).astype(np.float32)
                test_patch_1 = torch.from_numpy(test_patch_1).cuda()
                test_patch_2 = torch.from_numpy(test_patch_2).cuda()
                with torch.no_grad():
                    img_mask, loss_mask = context_mask(test_patch_1, mask_ratio)
                    patch_12 = test_patch_1 * img_mask + test_patch_2 * (1 - img_mask)
                    patch_21 = test_patch_2 * img_mask + test_patch_1 * (1 - img_mask)
                    yo1, _ = model(test_patch_1)
                    yo2, _ = model(test_patch_2)
                    y12, _ = model(patch_12)
                    y21, _ = model(patch_21)
                    ym1 = y12 * img_mask + y21 * (1 - img_mask)
                    ym2 = y12 * (1 - img_mask) + y21 * img_mask
                    yo1 = F.softmax(yo1, dim=1)
                    yo2 = F.softmax(yo2, dim=1)
                    ym1 = F.softmax(ym1, dim=1)
                    ym2 = F.softmax(ym2, dim=1)
                    # y12 = F.softmax(y12, dim=1)
                    # y21 = F.softmax(y21, dim=1)
                    # ym1 = F.softmax(ym1, dim=1)
                    # ym2 = F.softmax(ym2, dim=1)
                    # yf1 = 0.8 * y12 + 0.2 * ym1
                    # yf2 = 0.8 * y21 + 0.2 * ym2

                yo1 = yo1.cpu().data.numpy()
                yo1 = yo1[0,1,:,:,:]
                yo2 = yo2.cpu().data.numpy()
                yo2 = yo2[0, 1, :, :, :]
                ym1 = ym1.cpu().data.numpy()
                ym1 = ym1[0, 1, :, :, :]
                ym2 = ym2.cpu().data.numpy()
                ym2 = ym2[0,1,:,:,:]

                score_map_1_o[:, xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] \
                  = score_map_1_o[:, xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] + yo1
                score_map_1_m[:, xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] \
                  = score_map_1_m[:, xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] + ym1
                score_map_2_o[:, xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] \
                  = score_map_2_o[:, xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] + yo2
                score_map_2_m[:, xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] \
                  = score_map_2_m[:, xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] + ym2
                cnt[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] \
                  = cnt[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] + 1
    score_map_1_o = score_map_1_o/np.expand_dims(cnt,axis=0)
    score_map_1_m = score_map_1_m/np.expand_dims(cnt,axis=0)
    score_map_2_o = score_map_2_o/np.expand_dims(cnt,axis=0)
    score_map_2_m = score_map_2_m/np.expand_dims(cnt,axis=0)
    label_map_1_o = (score_map_1_o[0]>0.5).astype(np.int)
    label_map_1_m = (score_map_1_m[0]>0.9).astype(np.int)
    label_map_1_o = getLargestCC(label_map_1_o)
    label_map_1_m = getLargestCC(label_map_1_m)
    label_map_1 = ((label_map_1_o+label_map_1_m)>=1.0).astype(np.int)
    label_map_2_o = (score_map_2_o[0]>0.5).astype(np.int)
    label_map_2_m = (score_map_2_m[0]>0.9).astype(np.int)
    label_map_2_o = getLargestCC(label_map_2_o)
    label_map_2_m = getLargestCC(label_map_2_m)
    label_map_2 = ((label_map_2_o+label_map_2_m)>=1.0).astype(np.int)
    if add_pad:
        label_map_1 = label_map_1[wl_pad:wl_pad+w, hl_pad:hl_pad+h, dl_pad:dl_pad+d]
        score_map_1_o = score_map_1_o[:, wl_pad:wl_pad+w, hl_pad:hl_pad+h, dl_pad:dl_pad+d]
        label_map_2 = label_map_2[wl_pad:wl_pad+w, hl_pad:hl_pad+h, dl_pad:dl_pad+d]
        score_map_2_o = score_map_2_o[:, wl_pad:wl_pad+w, hl_pad:hl_pad+h, dl_pad:dl_pad+d]
    label_map_1 = label_map_1[wlpad1:wlpad1+w1, hlpad1:hlpad1+h1, dlpad1:dlpad1+d1]
    score_map_1 = score_map_1_o[:, wlpad1:wlpad1+w1, hlpad1:hlpad1+h1, dlpad1:dlpad1+d1]
    label_map_2 = label_map_2[wlpad2:wlpad2+w2, hlpad2:hlpad2+h2, dlpad2:dlpad2+d2]
    score_map_2 = score_map_2_o[:, wlpad2:wlpad2+w2, hlpad2:hlpad2+h2, dlpad2:dlpad2+d2]

    return label_map_1, score_map_1, label_map_2, score_map_2

# def test_double_case(model, image_1, image_2, stride_xy, stride_z, patch_size, num_classes=1):
#     w1, h1, d1 = image_1.shape
#     w2, h2, d2 = image_2.shape
#     wf = max(w1, w2)
#     hf = max(h1, h2)
#     df = max(d1, d2)
#     wpad1 = wf - w1
#     wpad2 = wf - w2
#     hpad1 = hf - h1
#     hpad2 = hf - h2
#     dpad1 = df - d1
#     dpad2 = df - d2
#     wlpad1, wrpad1, wlpad2, wrpad2 = wpad1 // 2, wpad1 - wpad1 // 2, wpad2 // 2, wpad2 - wpad2 // 2
#     hlpad1, hrpad1, hlpad2, hrpad2 = hpad1 // 2, hpad1 - hpad1 // 2, hpad2 // 2, hpad2 - hpad2 // 2
#     dlpad1, drpad1, dlpad2, drpad2 = dpad1 // 2, dpad1 - dpad1 // 2, dpad2 // 2, dpad2 - dpad2 // 2
#     image_1 = np.pad(image_1, [(wlpad1, wrpad1), (hlpad1, hrpad1), (dlpad1, drpad1)], mode='constant', constant_values=0)
#     image_2 = np.pad(image_2, [(wlpad2, wrpad2), (hlpad2, hrpad2), (dlpad2, drpad2)], mode='constant', constant_values=0)
#     w, h, d = wf, hf, df
#     add_pad = False
#     if w < patch_size[0]:
#         w_pad = patch_size[0] - w
#         add_pad = True
#     else:
#         w_pad = 0
#     if h < patch_size[1]:
#         h_pad = patch_size[1] - h
#         add_pad = True
#     else:
#         h_pad = 0
#     if d < patch_size[2]:
#         d_pad = patch_size[2] - d
#         add_pad = True
#     else:
#         d_pad = 0
#     wl_pad, wr_pad = w_pad // 2, w_pad - w_pad // 2
#     hl_pad, hr_pad = h_pad // 2, h_pad - h_pad // 2
#     dl_pad, dr_pad = d_pad // 2, d_pad - d_pad // 2
#     if add_pad:
#         image_1 = np.pad(image_1, [(wl_pad, wr_pad), (hl_pad, hr_pad), (dl_pad, dr_pad)], mode='constant', constant_values=0)
#         image_2 = np.pad(image_2, [(wl_pad, wr_pad), (hl_pad, hr_pad), (dl_pad, dr_pad)], mode='constant', constant_values=0)
#     ww, hh, dd = image_1.shape
#     sx = math.ceil((ww - patch_size[0]) / stride_xy) + 1
#     sy = math.ceil((hh - patch_size[1]) / stride_xy) + 1
#     sz = math.ceil((dd - patch_size[2]) / stride_z) + 1
#     # print("{}, {}, {}".format(sx, sy, sz))
#     score_map_1 = np.zeros((num_classes,) + image_1.shape).astype(np.float32)
#     score_map_2 = np.zeros((num_classes,) + image_2.shape).astype(np.float32)
#     cnt = np.zeros(image_1.shape).astype(np.float32)
#     mask_ratio = 2 / 3
#     for x in range(0, sx):
#         xs = min(stride_xy*x, ww-patch_size[0])
#         for y in range(0, sy):
#             ys = min(stride_xy * y,hh-patch_size[1])
#             for z in range(0, sz):
#                 zs = min(stride_z * z, dd-patch_size[2])
#                 test_patch_1 = image_1[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]]
#                 test_patch_2 = image_2[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]]
#                 test_patch_1 = np.expand_dims(np.expand_dims(test_patch_1, axis=0), axis=0).astype(np.float32)
#                 test_patch_2 = np.expand_dims(np.expand_dims(test_patch_2, axis=0), axis=0).astype(np.float32)
#                 test_patch_1 = torch.from_numpy(test_patch_1).cuda()
#                 test_patch_2 = torch.from_numpy(test_patch_2).cuda()
#                 with torch.no_grad():
#                     img_mask, loss_mask = context_mask(test_patch_1, mask_ratio)
#                     patch_12 = test_patch_1 * img_mask + test_patch_2 * (1 - img_mask)
#                     patch_21 = test_patch_2 * img_mask + test_patch_1 * (1 - img_mask)
#                     yo1, _ = model(test_patch_1)
#                     yo2, _ = model(test_patch_2)
#                     y12, _ = model(patch_12)
#                     y21, _ = model(patch_21)
#                     ym1 = y12 * img_mask + y21 * (1 - img_mask)
#                     ym2 = y12 * (1 - img_mask) + y21 * img_mask
#                     y1 = 0.9 * yo1 + 0.1 * ym1
#                     y2 = 0.9 * yo2 + 0.1 * ym2
#                     yf1 = F.softmax(y1, dim=1)
#                     yf2 = F.softmax(y2, dim=1)
#                     # y12 = F.softmax(y12, dim=1)
#                     # y21 = F.softmax(y21, dim=1)
#                     # ym1 = F.softmax(ym1, dim=1)
#                     # ym2 = F.softmax(ym2, dim=1)
#                     # yf1 = 0.8 * y12 + 0.2 * ym1
#                     # yf2 = 0.8 * y21 + 0.2 * ym2
#
#                 yf1 = yf1.cpu().data.numpy()
#                 yf1 = yf1[0,1,:,:,:]
#                 yf2 = yf2.cpu().data.numpy()
#                 yf2 = yf2[0,1,:,:,:]
#
#                 score_map_1[:, xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] \
#                   = score_map_1[:, xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] + yf1
#                 score_map_2[:, xs:xs + patch_size[0], ys:ys + patch_size[1], zs:zs + patch_size[2]] \
#                     = score_map_2[:, xs:xs + patch_size[0], ys:ys + patch_size[1], zs:zs + patch_size[2]] + yf2
#                 cnt[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] \
#                   = cnt[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] + 1
#     score_map_1 = score_map_1/np.expand_dims(cnt,axis=0)
#     score_map_2 = score_map_2 / np.expand_dims(cnt, axis=0)
#     label_map_1 = (score_map_1[0]>0.5).astype(np.int)
#     label_map_2 = (score_map_2[0]>0.5).astype(np.int)
#     if add_pad:
#         label_map_1 = label_map_1[wl_pad:wl_pad+w, hl_pad:hl_pad+h, dl_pad:dl_pad+d]
#         score_map_1 = score_map_1[:, wl_pad:wl_pad+w, hl_pad:hl_pad+h, dl_pad:dl_pad+d]
#         label_map_2 = label_map_2[wl_pad:wl_pad+w, hl_pad:hl_pad+h, dl_pad:dl_pad+d]
#         score_map_2 = score_map_2[:, wl_pad:wl_pad+w, hl_pad:hl_pad+h, dl_pad:dl_pad+d]
#     label_map_1 = label_map_1[wlpad1:wlpad1+w1, hlpad1:hlpad1+h1, dlpad1:dlpad1+d1]
#     score_map_1 = score_map_1[:, wlpad1:wlpad1+w1, hlpad1:hlpad1+h1, dlpad1:dlpad1+d1]
#     label_map_2 = label_map_2[wlpad2:wlpad2+w2, hlpad2:hlpad2+h2, dlpad2:dlpad2+d2]
#     score_map_2 = score_map_2[:, wlpad2:wlpad2+w2, hlpad2:hlpad2+h2, dlpad2:dlpad2+d2]
#
#     return label_map_1, score_map_1, label_map_2, score_map_2


def test_single_case(model, image, stride_xy, stride_z, patch_size, num_classes=1):
    w, h, d = image.shape

    # if the size of image is less than patch_size, then padding it
    add_pad = False
    if w < patch_size[0]:
        w_pad = patch_size[0]-w
        add_pad = True
    else:
        w_pad = 0
    if h < patch_size[1]:
        h_pad = patch_size[1]-h
        add_pad = True
    else:
        h_pad = 0
    if d < patch_size[2]:
        d_pad = patch_size[2]-d
        add_pad = True
    else:
        d_pad = 0
    wl_pad, wr_pad = w_pad//2,w_pad-w_pad//2
    hl_pad, hr_pad = h_pad//2,h_pad-h_pad//2
    dl_pad, dr_pad = d_pad//2,d_pad-d_pad//2
    if add_pad:
        image = np.pad(image, [(wl_pad,wr_pad),(hl_pad,hr_pad), (dl_pad, dr_pad)], mode='constant', constant_values=0)
    ww,hh,dd = image.shape

    sx = math.ceil((ww - patch_size[0]) / stride_xy) + 1
    sy = math.ceil((hh - patch_size[1]) / stride_xy) + 1
    sz = math.ceil((dd - patch_size[2]) / stride_z) + 1
    # print("{}, {}, {}".format(sx, sy, sz))
    score_map = np.zeros((num_classes, ) + image.shape).astype(np.float32)
    cnt = np.zeros(image.shape).astype(np.float32)

    for x in range(0, sx):
        xs = min(stride_xy*x, ww-patch_size[0])
        for y in range(0, sy):
            ys = min(stride_xy * y,hh-patch_size[1])
            for z in range(0, sz):
                zs = min(stride_z * z, dd-patch_size[2])
                test_patch = image[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]]
                test_patch = np.expand_dims(np.expand_dims(test_patch,axis=0),axis=0).astype(np.float32)
                test_patch = torch.from_numpy(test_patch).cuda()

                with torch.no_grad():
                    y1, _ = model(test_patch)
                    y = F.softmax(y1, dim=1)

                y = y.cpu().data.numpy()
                y = y[0,1,:,:,:]
                score_map[:, xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] \
                  = score_map[:, xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] + y
                cnt[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] \
                  = cnt[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] + 1
    score_map = score_map/np.expand_dims(cnt,axis=0)
    label_map = (score_map[0]>0.5).astype(np.int)
    if add_pad:
        label_map = label_map[wl_pad:wl_pad+w,hl_pad:hl_pad+h,dl_pad:dl_pad+d]
        score_map = score_map[:,wl_pad:wl_pad+w,hl_pad:hl_pad+h,dl_pad:dl_pad+d]
    return label_map, score_map


def var_all_case_LA_plus(model_l, model_r, num_classes, patch_size=(112, 112, 80), stride_xy=18, stride_z=4):
   
    with open('/data/byh_data/SSNet_data/LA/test.list', 'r') as f:
        image_list = f.readlines()
    image_list = ["/data/byh_data/SSNet_data/LA/2018LA_Seg_Training Set/" + item.replace('\n', '') + "/mri_norm2.h5" for item in image_list]
    loader = tqdm(image_list)
    total_dice = 0.0
    for image_path in loader:
        h5f = h5py.File(image_path, 'r')
        image = h5f['image'][:]
        label = h5f['label'][:]
        prediction, score_map = test_single_case_plus(model_l, model_r, image, stride_xy, stride_z, patch_size, num_classes=num_classes)
        if np.sum(prediction)==0:
            dice = 0
        else:
            dice = metric.binary.dc(prediction, label)
        total_dice += dice
    avg_dice = total_dice / len(image_list)
    print('average metric is {}'.format(avg_dice))
    return avg_dice

def test_all_case_plus(model_l, model_r, image_list, num_classes, patch_size=(112, 112, 80), stride_xy=18, stride_z=4, save_result=True, test_save_path=None, preproc_fn=None, metric_detail=0, nms=0):
    
    loader = tqdm(image_list) if not metric_detail else image_list
    total_metric = 0.0
    ith = 0
    for image_path in loader:
        # id = image_path.split('/')[-2]
        h5f = h5py.File(image_path, 'r')
        image = h5f['image'][:]
        label = h5f['label'][:]
        if preproc_fn is not None:
            image = preproc_fn(image)
        prediction, score_map = test_single_case_plus(model_l, model_r, image, stride_xy, stride_z, patch_size, num_classes=num_classes)
        if nms:
            prediction = getLargestCC(prediction)
            
        if np.sum(prediction)==0:
            single_metric = (0,0,0,0)
        else:
            single_metric = calculate_metric_percase(prediction, label[:])
            
        if metric_detail:
            print('%02d,\t%.5f, %.5f, %.5f, %.5f' % (ith, single_metric[0], single_metric[1], single_metric[2], single_metric[3]))

        total_metric += np.asarray(single_metric)
        
        if save_result:
            nib.save(nib.Nifti1Image(prediction.astype(np.float32), np.eye(4)), test_save_path +  "%02d_pred.nii.gz" % ith)
            #nib.save(nib.Nifti1Image(score_map[0].astype(np.float32), np.eye(4)), test_save_path +  "%02d_scores.nii.gz" % ith)
            nib.save(nib.Nifti1Image(image[:].astype(np.float32), np.eye(4)), test_save_path + "%02d_img.nii.gz" % ith)
            nib.save(nib.Nifti1Image(label[:].astype(np.float32), np.eye(4)), test_save_path + "%02d_gt.nii.gz" % ith)
        ith += 1

    avg_metric = total_metric / len(image_list)
    print('average metric is {}'.format(avg_metric))
    
    with open(test_save_path+'../performance.txt', 'w') as f:
        f.writelines('average metric is {} \n'.format(avg_metric))
    return avg_metric

def test_single_case_plus(model_l, model_r, image, stride_xy, stride_z, patch_size, num_classes=1):
    w, h, d = image.shape

    # if the size of image is less than patch_size, then padding it
    add_pad = False
    if w < patch_size[0]:
        w_pad = patch_size[0]-w
        add_pad = True
    else:
        w_pad = 0
    if h < patch_size[1]:
        h_pad = patch_size[1]-h
        add_pad = True
    else:
        h_pad = 0
    if d < patch_size[2]:
        d_pad = patch_size[2]-d
        add_pad = True
    else:
        d_pad = 0
    wl_pad, wr_pad = w_pad//2,w_pad-w_pad//2
    hl_pad, hr_pad = h_pad//2,h_pad-h_pad//2
    dl_pad, dr_pad = d_pad//2,d_pad-d_pad//2
    if add_pad:
        image = np.pad(image, [(wl_pad,wr_pad),(hl_pad,hr_pad), (dl_pad, dr_pad)], mode='constant', constant_values=0)
    ww,hh,dd = image.shape

    sx = math.ceil((ww - patch_size[0]) / stride_xy) + 1
    sy = math.ceil((hh - patch_size[1]) / stride_xy) + 1
    sz = math.ceil((dd - patch_size[2]) / stride_z) + 1
    # print("{}, {}, {}".format(sx, sy, sz))
    score_map = np.zeros((num_classes, ) + image.shape).astype(np.float32)
    cnt = np.zeros(image.shape).astype(np.float32)

    for x in range(0, sx):
        xs = min(stride_xy*x, ww-patch_size[0])
        for y in range(0, sy):
            ys = min(stride_xy * y,hh-patch_size[1])
            for z in range(0, sz):
                zs = min(stride_z * z, dd-patch_size[2])
                test_patch = image[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]]
                test_patch = np.expand_dims(np.expand_dims(test_patch,axis=0),axis=0).astype(np.float32)
                test_patch = torch.from_numpy(test_patch).cuda()

                with torch.no_grad():
                    y1_l, _ = model_l(test_patch)
                    y1_r, _ = model_r(test_patch)
                    y1 = (y1_l + y1_r) / 2
                    y = F.softmax(y1, dim=1)

                y = y.cpu().data.numpy()
                y = y[0,1,:,:,:]
                score_map[:, xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] \
                  = score_map[:, xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] + y
                cnt[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] \
                  = cnt[xs:xs+patch_size[0], ys:ys+patch_size[1], zs:zs+patch_size[2]] + 1
    score_map = score_map/np.expand_dims(cnt,axis=0)
    label_map = (score_map[0]>0.5).astype(np.int)
    if add_pad:
        label_map = label_map[wl_pad:wl_pad+w,hl_pad:hl_pad+h,dl_pad:dl_pad+d]
        score_map = score_map[:,wl_pad:wl_pad+w,hl_pad:hl_pad+h,dl_pad:dl_pad+d]
    return label_map, score_map


def calculate_metric_percase(pred, gt):
    dice = metric.binary.dc(pred, gt)
    jc = metric.binary.jc(pred, gt)
    hd = metric.binary.hd95(pred, gt)
    asd = metric.binary.asd(pred, gt)

    return dice, jc, hd, asd
